{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting Started**\n",
        "\n",
        "We first install the required concrete-ml packages for this Colab instance.\n",
        "\n",
        "The packages need to be reinstalled each time the notebook is opened since the runtime is deleted after roughly 90 minutes of inactivity, but this can be circumvented by storing the packages in your Google Drive and importing from those instead."
      ],
      "metadata": {
        "id": "BNFSQzp0QHZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XgQnkuMLJOxc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54542398-f510-4c12-b669-d73b2ca55636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (65.6.3)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 65.6.3\n",
            "    Uninstalling setuptools-65.6.3:\n",
            "      Successfully uninstalled setuptools-65.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "concrete-ml 1.0.2 requires setuptools==65.6.3, but you have setuptools 67.8.0 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-67.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: concrete-ml==1.0.2 in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.26.155)\n",
            "Requirement already satisfied: brevitas==0.8.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.8.0)\n",
            "Requirement already satisfied: concrete-python==1.0.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.0.0)\n",
            "Requirement already satisfied: fastapi<0.94.0,>=0.93.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.93.0)\n",
            "Requirement already satisfied: hummingbird-ml[onnx]==0.4.8 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.4.8)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.23.5)\n",
            "Requirement already satisfied: onnx==1.13.1 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: onnxoptimizer==0.3.10 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.3.10)\n",
            "Requirement already satisfied: onnxruntime==1.13.1 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (3.20.3)\n",
            "Requirement already satisfied: python-multipart<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.0.6)\n",
            "Requirement already satisfied: scikit-learn==1.1.3 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.1.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.10.1)\n",
            "Collecting setuptools==65.6.3 (from concrete-ml==1.0.2)\n",
            "  Using cached setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "Requirement already satisfied: skops==0.5.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.5.0)\n",
            "Requirement already satisfied: skorch==0.11.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.11.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions==4.4.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (4.4.0)\n",
            "Requirement already satisfied: uvicorn<0.22.0,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (0.21.1)\n",
            "Requirement already satisfied: xgboost==1.6.2 in /usr/local/lib/python3.10/dist-packages (from concrete-ml==1.0.2) (1.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas==0.8.0->concrete-ml==1.0.2) (23.1)\n",
            "Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.10/dist-packages (from brevitas==0.8.0->concrete-ml==1.0.2) (2.0.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.10/dist-packages (from concrete-python==1.0.0->concrete-ml==1.0.2) (3.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml[onnx]==0.4.8->concrete-ml==1.0.2) (0.3.6)\n",
            "Requirement already satisfied: onnxconverter-common>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml[onnx]==0.4.8->concrete-ml==1.0.2) (1.13.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml[onnx]==0.4.8->concrete-ml==1.0.2) (5.9.5)\n",
            "Requirement already satisfied: onnxmltools<=1.11.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml[onnx]==0.4.8->concrete-ml==1.0.2) (1.11.0)\n",
            "Requirement already satisfied: skl2onnx<=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml[onnx]==0.4.8->concrete-ml==1.0.2) (1.12)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete-ml==1.0.2) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete-ml==1.0.2) (23.3.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete-ml==1.0.2) (1.11.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->concrete-ml==1.0.2) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->concrete-ml==1.0.2) (3.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from skops==0.5.0->concrete-ml==1.0.2) (0.15.1)\n",
            "Requirement already satisfied: tabulate>=0.8.8 in /usr/local/lib/python3.10/dist-packages (from skops==0.5.0->concrete-ml==1.0.2) (0.8.10)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->concrete-ml==1.0.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->concrete-ml==1.0.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->concrete-ml==1.0.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->concrete-ml==1.0.2) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->concrete-ml==1.0.2) (0.40.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.155 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.23.5->concrete-ml==1.0.2) (1.29.155)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.23.5->concrete-ml==1.0.2) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.23.5->concrete-ml==1.0.2) (0.6.1)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.94.0,>=0.93.0->concrete-ml==1.0.2) (1.10.7)\n",
            "Requirement already satisfied: starlette<0.26.0,>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.94.0,>=0.93.0->concrete-ml==1.0.2) (0.25.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.22.0,>=0.21.0->concrete-ml==1.0.2) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.22.0,>=0.21.0->concrete-ml==1.0.2) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.155->boto3<2.0.0,>=1.23.5->concrete-ml==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.155->boto3<2.0.0,>=1.23.5->concrete-ml==1.0.2) (1.26.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml==1.0.2) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml==1.0.2) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml==1.0.2) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml==1.0.2) (6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.26.0,>=0.25.0->fastapi<0.94.0,>=0.93.0->concrete-ml==1.0.2) (3.6.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime==1.13.1->concrete-ml==1.0.2) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.13.1->concrete-ml==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.26.0,>=0.25.0->fastapi<0.94.0,>=0.93.0->concrete-ml==1.0.2) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.26.0,>=0.25.0->fastapi<0.94.0,>=0.93.0->concrete-ml==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.155->boto3<2.0.0,>=1.23.5->concrete-ml==1.0.2) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml==1.0.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml==1.0.2) (2.0.12)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.8.0\n",
            "    Uninstalling setuptools-67.8.0:\n",
            "      Successfully uninstalled setuptools-67.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#reinstall packages (required unless the packages are stored in your google drive)\n",
        "!pip install -U pip wheel setuptools\n",
        "!pip install concrete-ml==1.0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Download required files and compiled model, and instantiate on-disk network**"
      ],
      "metadata": {
        "id": "_6wgckvyJwfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, platform, time, os, subprocess, numpy, stat\n",
        "from pandas import DataFrame as pd\n",
        "from pandas import read_csv\n",
        "from shutil import copyfile\n",
        "from tempfile import TemporaryDirectory\n",
        "from concrete.ml.deployment import FHEModelClient, FHEModelDev, FHEModelServer\n",
        "\n",
        "def getRequiredFiles():\n",
        "    files = [\n",
        "        r\"https://github.com/gcrosario/concreteML-FHE-Tumor-Classification/raw/master/FHE-Compiled-Model/LR-Kbest20-Trial3/client.zip\",\n",
        "        r\"https://raw.githubusercontent.com/gcrosario/concreteML-FHE-Tumor-Classification/master/FHE-Compiled-Model/kbest-top-features.txt\",\n",
        "        r\"https://github.com/gcrosario/concreteML-FHE-Tumor-Classification/raw/master/FHE-Compiled-Model/LR-Kbest20-Trial3/server.zip\",\n",
        "        r\"https://raw.githubusercontent.com/gcrosario/concreteML-FHE-Tumor-Classification/master/testing-samples/ependymoma_sample.csv\",\n",
        "        r\"https://raw.githubusercontent.com/gcrosario/concreteML-FHE-Tumor-Classification/master/testing-samples/glioblastoma_sample.csv\",\n",
        "        ]\n",
        "    for file in files:\n",
        "        print(file.split(\"/\")[-1].replace(\"%20\", \" \"))\n",
        "        if file.split(\"/\")[-1].replace(\"%20\", \" \") not in os.listdir(\"/content\"):\n",
        "            download(file, \"/content\")\n",
        "\n",
        "def download(url, dest_folder):\n",
        "    if not os.path.exists(dest_folder):\n",
        "        os.makedirs(dest_folder)\n",
        "\n",
        "    filename = url.split('/')[-1].replace(\" \", \"_\")\n",
        "    file_path = os.path.join(dest_folder, filename)\n",
        "\n",
        "    r = requests.get(url, stream=True)\n",
        "\n",
        "    if r.ok:\n",
        "        print(\"saving to\", os.path.abspath(file_path))\n",
        "        with open(file_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=1024 * 8):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    f.flush()\n",
        "                    os.fsync(f.fileno())\n",
        "    else:  # HTTP status code 4XX/5XX\n",
        "        print(\"Download failed: status code {}\\n{}\".format(r.status_code, r.text))\n",
        "\n",
        "def get_size(self, file_path, unit='bytes'):\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        exponents_map = {'bytes': 0, 'kb': 1, 'mb': 2, 'gb': 3}\n",
        "        if unit not in exponents_map:\n",
        "            raise ValueError(\"Must select from \\\n",
        "            ['bytes', 'kb', 'mb', 'gb']\")\n",
        "        else:\n",
        "            size = file_size / 1024 ** exponents_map[unit]\n",
        "            return round(size, 3)\n",
        "\n",
        "getRequiredFiles()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YMOAYISJv8g",
        "outputId": "ca58835a-0a1a-490b-bd05-dbc2a1793328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client.zip\n",
            "saving to /content/client.zip\n",
            "kbest-top-features.txt\n",
            "saving to /content/kbest-top-features.txt\n",
            "server.zip\n",
            "saving to /content/server.zip\n",
            "ependymoma_sample.csv\n",
            "saving to /content/ependymoma_sample.csv\n",
            "glioblastoma_sample.csv\n",
            "saving to /content/glioblastoma_sample.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For demonstration purposes, an on-disk network will be simulated to serve as our way to communicate with the server. The code for the on-disk network was taken from Concrete-ML's [sample ClientServer notebook](https://github.com/zama-ai/concrete-ml/blob/release/1.0.x/docs/advanced_examples/ClientServer.ipynb)."
      ],
      "metadata": {
        "id": "GBrcawI5PkhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OnDiskNetwork:\n",
        "    \"\"\"Simulate a network on disk.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Create 3 temporary folder for server, client and dev with tempfile\n",
        "        self.server_dir = TemporaryDirectory()  # pylint: disable=consider-using-with\n",
        "        self.client_dir = TemporaryDirectory()  # pylint: disable=consider-using-with\n",
        "        self.dev_dir = TemporaryDirectory()  # pylint: disable=consider-using-with\n",
        "        print(\"On-disk network initialized!\\n\")\n",
        "\n",
        "    def client_send_evaluation_key_to_server(self, serialized_evaluation_keys):\n",
        "        \"\"\"Send the public key to the server.\"\"\"\n",
        "        with open(self.server_dir.name + \"/serialized_evaluation_keys.ekl\", \"wb\") as f:\n",
        "            f.write(serialized_evaluation_keys)\n",
        "\n",
        "        print(\"Evaluation keys sent to server.\\n\")\n",
        "\n",
        "    def client_send_input_to_server_for_prediction(self, encrypted_input):\n",
        "        \"\"\"Send the input to the server and execute on the server in FHE.\"\"\"\n",
        "        with open(self.server_dir.name + \"/serialized_evaluation_keys.ekl\", \"rb\") as f:\n",
        "            serialized_evaluation_keys = f.read()\n",
        "        time_begin = time.time()\n",
        "        encrypted_prediction = FHEModelServer(self.server_dir.name).run(\n",
        "            encrypted_input, serialized_evaluation_keys\n",
        "        )\n",
        "        time_end = time.time()\n",
        "        with open(self.server_dir.name + \"/encrypted_prediction.enc\", \"wb\") as f:\n",
        "            f.write(encrypted_prediction)\n",
        "        return time_end - time_begin\n",
        "\n",
        "    def dev_send_model_to_server(self):\n",
        "        \"\"\"Send the model to the server.\"\"\"\n",
        "        copyfile(self.dev_dir.name + \"/server.zip\", self.server_dir.name + \"/server.zip\")\n",
        "\n",
        "        print(\"Model sent to server.\\n\")\n",
        "\n",
        "    def server_send_encrypted_prediction_to_client(self):\n",
        "        \"\"\"Send the encrypted prediction to the client.\"\"\"\n",
        "        with open(self.server_dir.name + \"/encrypted_prediction.enc\", \"rb\") as f:\n",
        "            encrypted_prediction = f.read()\n",
        "        return encrypted_prediction\n",
        "\n",
        "    def dev_send_clientspecs_to_client(self):\n",
        "        \"\"\"Send the client specs to the client.\"\"\"\n",
        "        copyfile(self.dev_dir.name + \"/client.zip\", self.client_dir.name + \"/client.zip\")\n",
        "\n",
        "        print(\"Successfully sent client specs to client.\\n\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clean up the temporary folders.\"\"\"\n",
        "        self.server_dir.cleanup()\n",
        "        self.client_dir.cleanup()\n",
        "        self.dev_dir.cleanup()\n",
        "\n",
        "    def move_client_server_specs_to_network(self):\n",
        "        copyfile(\"/content/server.zip\" , self.dev_dir.name + \"/server.zip\")\n",
        "        copyfile(\"/content/client.zip\" , self.dev_dir.name + \"/client.zip\")\n",
        "        print(\"Compiled model and client specs copied to on-disk network.\\n\")\n",
        "\n",
        "# Let's instantiate the network and move our downloaded demo files into it\n",
        "network = OnDiskNetwork()\n",
        "network.move_client_server_specs_to_network()\n",
        "\n",
        "# List files inside the temporary development directory\n",
        "!ls -lh $network.dev_dir.name"
      ],
      "metadata": {
        "id": "1l4uDTJ4P7qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0de3c7a-3f81-49b3-89aa-5f4200469434"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On-disk network initialized!\n",
            "\n",
            "Compiled model and client specs copied to on-disk network.\n",
            "\n",
            "total 12K\n",
            "-rw-r--r-- 1 root root 1.1K Jun 19 10:23 client.zip\n",
            "-rw-r--r-- 1 root root 5.4K Jun 19 10:23 server.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this is a guide on the overall production workflow of the system, we won't be going through the training phase here, and will instead be using the compiled model downloaded from the Github repository.\n",
        "\n",
        "At this point, we then move our compiled model onto the server, where it can then be used for classification."
      ],
      "metadata": {
        "id": "GfpIp1IqQ93X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's send the model to the server\n",
        "network.dev_send_model_to_server()\n",
        "!ls -lh $network.server_dir.name"
      ],
      "metadata": {
        "id": "I0N9bTpdTTbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509a6ff7-7366-43ad-9862-b22984e80774"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model sent to server.\n",
            "\n",
            "total 8.0K\n",
            "-rw-r--r-- 1 root root 5.4K Jun 19 10:23 server.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our compiled model on our server, we only need to send the client specifications to our simulated client to proceed with the next step."
      ],
      "metadata": {
        "id": "PqP3dqDDTuPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's send the clientspecs and evaluation key to the client\n",
        "network.dev_send_clientspecs_to_client()\n",
        "!ls -lh $network.client_dir.name"
      ],
      "metadata": {
        "id": "QLCcEM2TTudY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f2a301-c12c-4824-fd26-aae6fbabc1f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully sent client specs to client.\n",
            "\n",
            "total 4.0K\n",
            "-rw-r--r-- 1 root root 1.1K Jun 19 10:23 client.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Apply Feature Selection**\n",
        "\n",
        "Before moving on to data encryption, the client must first apply feature selection on the initial input file.\n",
        "\n",
        "Using the text file containing the list of final features to be used in the model, we will create a \"feature_selection_output.csv\" file and this will be our final plaintext input for encryption."
      ],
      "metadata": {
        "id": "g52NeQziWsyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dropColumns(featSel_input, file = os.path.join(\"/content\", \"kbest-top-features.txt\")):\n",
        "        with open(file, \"r\") as feature_file:\n",
        "            features = [feature.strip() for feature in feature_file.readlines()]\n",
        "\n",
        "        feature_list = [\"samples\"] + features\n",
        "\n",
        "        drop_df = read_csv(featSel_input)\n",
        "        drop_df = drop_df[[column.strip() for column in feature_list]]\n",
        "        drop_df.to_csv(\"./feature_selection_output.csv\", index=False, header=True)\n",
        "\n",
        "required_folder_names = [\"testing_samples\", \"keys\", \"predictions\"]\n",
        "\n",
        "#create required folders\n",
        "for name in required_folder_names:\n",
        "    if not os.path.exists(os.path.join(\"/content\", f\"{name}\")):\n",
        "        os.mkdir(os.path.join(\"/content\", f\"{name}\"))\n",
        "\n",
        "#move testing samples files to \"testing_samples\"\n",
        "for filename in os.listdir(\"/content\"):\n",
        "  if filename.endswith(\".csv\"):\n",
        "    os.rename(filename, \"testing_samples/\" + filename)\n",
        "\n",
        "featSel_input = os.path.join(\"/content/testing_samples/\", f\"ependymoma_sample.csv\")\n",
        "dropColumns(featSel_input)\n",
        "\n",
        "print(\"Feature Selection Done!\")"
      ],
      "metadata": {
        "id": "CLXThRrWWFVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f811cd3-6474-479b-cfdc-0ba3daa7caeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Selection Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Generate keys on the client machine**\n",
        "After performing feature selection, we can now perform encryption to obtain the final input file that will be sent to the server. But first, we have to generate the private and evaluation keys. We also need to send the evaluation keys to the server."
      ],
      "metadata": {
        "id": "exRdyEDRKJpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = network.client_dir.name\n",
        "key_dir = network.client_dir.name\n",
        "\n",
        "fhe_model_client = FHEModelClient(network.client_dir.name, key_dir=network.client_dir.name)\n",
        "\n",
        "# The client first need to create the private and evaluation keys.\n",
        "fhe_model_client.generate_private_and_evaluation_keys()\n",
        "\n",
        "serialized_evaluation_keys = fhe_model_client.get_serialized_evaluation_keys()\n",
        "\n",
        "# Let's send this evaluation key to the server (this has to be done only once)\n",
        "network.client_send_evaluation_key_to_server(serialized_evaluation_keys)\n",
        "\n",
        "print(\"Private and evaluation keys generated.\\n\")\n",
        "\n",
        "network.client_send_evaluation_key_to_server(serialized_evaluation_keys)\n",
        "\n",
        "!ls -lh $network.server_dir.name"
      ],
      "metadata": {
        "id": "RJe2GyBWqFp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8b6a9f-f4f5-465d-a812-0aa7796ff5d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation keys sent to server.\n",
            "\n",
            "Private and evaluation keys generated.\n",
            "\n",
            "Evaluation keys sent to server.\n",
            "\n",
            "total 12K\n",
            "-rw-r--r-- 1 root root   24 Jun 19 10:26 serialized_evaluation_keys.ekl\n",
            "-rw-r--r-- 1 root root 5.4K Jun 19 10:23 server.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Encrypt Preprocessed Data**\n",
        "After performing feature selection, we can now perform encryption to obtain the final input file that will be sent to the server. But first, we have to generate the private and evaluation keys."
      ],
      "metadata": {
        "id": "wY0FqIWsnA-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the keys are generated, we can proceed to the encryption proper. Using **pandas** we will read our output from the previous selection step. This will then be our input for the encryption."
      ],
      "metadata": {
        "id": "3MuJRtqVkleQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the preprocessed input data\n",
        "encryption_input = os.path.join(\"/content\", f\"feature_selection_output.csv\")\n",
        "df = read_csv(encryption_input)\n",
        "arr_no_id = df.drop(columns=['samples']).to_numpy(dtype=\"uint16\")\n",
        "\n",
        "# encrypted rows for input to server\n",
        "encrypted_rows = []\n",
        "\n",
        "#encrypted dictionary for outputs\n",
        "count = 0\n",
        "\n",
        "data_dictionary = {}\n",
        "for id in df['samples']:\n",
        "    data_dictionary[count] = {'id':id, 'result':''}\n",
        "\n",
        "for row in range(0, arr_no_id.shape[0]):\n",
        "    clear_input = arr_no_id[[row],:]\n",
        "    encrypted_input = fhe_model_client.quantize_encrypt_serialize(clear_input)\n",
        "    print(\"Encrypting pre-processed data...\")\n",
        "    encrypted_rows.append(encrypted_input)\n",
        "\n",
        "encrypted_rows = encrypted_rows\n",
        "# print(encrypted_rows)\n",
        "\n",
        "# for row in encrypted_rows:\n",
        "#     print(\"Row: \", row[:10])\n",
        "\n",
        "print(\"Data Encryption DONE!\")\n",
        "\n",
        "# save the encrypted file and evaluation keys\n",
        "filename = \"encrypted_input.txt\"\n",
        "with open(os.path.join(\"/content\", filename), \"wb\") as enc_file:\n",
        "    for line in encrypted_rows:\n",
        "        enc_file.write(line)\n",
        "\n",
        "with open(os.path.join(\"/content\", f\"serialized_evaluation_keys.ekl\"), \"wb\") as f:\n",
        "    f.write(serialized_evaluation_keys)\n",
        "\n",
        "print(\"Encrypted inputs and key files saved to 'encrypted_input.txt' and 'serialized_evaluation_keys.ekl'.\")"
      ],
      "metadata": {
        "id": "V5fUuC0Sk9ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90984e1-ffb2-46b2-dce3-cb7c02461931"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encrypting pre-processed data...\n",
            "Data Encryption DONE!\n",
            "Encrypted inputs and key files saved to 'encrypted_input.txt' and 'serialized_evaluation_keys.ekl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Perform FHE Inference on the Server**\n",
        "Now that we have successfully encrypted our input data, we can now send it to the server and perform FHE inference."
      ],
      "metadata": {
        "id": "RnEh0jkloGAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print((\"Sending encrypted data to server...\"))\n",
        "\n",
        "execution_time = []\n",
        "execution_time += [network.client_send_input_to_server_for_prediction(encrypted_rows[0])]\n",
        "\n",
        "print(\"\\nFHE inference DONE! \\n\")\n",
        "print(f\"The execution time is {numpy.mean(execution_time):.4f} seconds.\")"
      ],
      "metadata": {
        "id": "KcACObv3oO-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b39cb72-2268-4cc4-8b73-66edcc0caa58"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending encrypted data to server...\n",
            "\n",
            "FHE inference DONE! \n",
            "\n",
            "The execution time is 0.0121 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encrypted_prediction = network.server_send_encrypted_prediction_to_client()\n",
        "print(\"Encrypted prediction sent to client!\")\n"
      ],
      "metadata": {
        "id": "TQXwmcxVsVel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fb3cb0-182a-4006-bb5b-be77d321431b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encrypted prediction sent to client!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Decrypt the encrypted prediction results**"
      ],
      "metadata": {
        "id": "3SR76mMcsGhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes_dict = {0: 'ependymoma', 1: 'glioblastoma', 2: 'medulloblastoma', 3: 'normal', 4: 'pilocytic_astrocytoma'}\n",
        "\n",
        "decrypted_predictions = []\n",
        "\n",
        "print(\"Now performing decryption on the prediction....\")\n",
        "\n",
        "decrypted_prediction = fhe_model_client.deserialize_decrypt_dequantize(encrypted_prediction)[0]\n",
        "\n",
        "decrypted_predictions.append(decrypted_prediction)\n",
        "\n",
        "decrypted_prediction_class = numpy.array(decrypted_predictions).argmax(axis=1)\n",
        "\n",
        "final_output = [classes_dict[i] for i in decrypted_prediction_class]\n",
        "\n",
        "print(\"\\nPrediction decryption DONE!\")"
      ],
      "metadata": {
        "id": "WPNOYsQirFz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377acce0-4779-4221-967c-41ee5263e700"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now performing decryption on the prediction....\n",
            "\n",
            "Prediction decryption DONE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The brain tumor classification of your input is: \")\n",
        "\n",
        "for output in final_output:\n",
        "  print(output)"
      ],
      "metadata": {
        "id": "0ADjgA5atS3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae6969e-7643-487f-81d5-b1678f883542"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The brain tumor classification of your input is: \n",
            "ependymoma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkzBGfnNsbD1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}